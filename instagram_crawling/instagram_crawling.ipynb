{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get('https://www.instagram.com')\n",
    "time.sleep(2)\n",
    "\n",
    "# email='****@naver.com'\n",
    "# input_id = driver.find_elements(By.CSS_SELECTOR,'input._aa4b')[0]\n",
    "# input_id.clear()\n",
    "# input_id.send_keys(email)\n",
    "# \n",
    "# password='****'\n",
    "# input_pw = driver.find_elements(By.CSS_SELECTOR,'input._aa4b')[1]\n",
    "# input_pw.clear()\n",
    "# input_pw.send_keys(password)\n",
    "# input_pw.submit()\n",
    "# time.sleep(30)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30cdaf6a0562a3d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "def insta_searching(word):\n",
    "  url ='https://www.instagram.com/explore/tags/' + word\n",
    "  return url\n",
    "\n",
    "def select_first(driver):\n",
    "  first = driver.find_element(By.CSS_SELECTOR,'div._aagw')\n",
    "  first.click()\n",
    "  time.sleep(5)\n",
    "\n",
    "def get_content(driver):\n",
    "  html = driver.page_source\n",
    "  soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "  try:\n",
    "    content = soup.select('div._a9zs > h1')[0].text\n",
    "    content = unicodedata.normalize('NFC',content)\n",
    "  except:\n",
    "    content=''\n",
    "\n",
    "  tags = re.findall(r'#[^\\s#,\\\\]+', content)\n",
    "  # print('tags', tags)\n",
    "  date = soup.select('time._a9ze._a9zf')[0]['datetime'][:10]\n",
    "  # print('date', date)\n",
    "  try:\n",
    "    like = soup.select('a.x1i10hfl.xjbqb8w.x1ejq31n.xd10rxx.x1sy0etr.x17r0tee.x972fbf.xcfux6l.x1qhh985.xm0m39n.x9f619.x1ypdohk.xt0psk2.xe8uvvx.xdj266r.x11i5rnm.xat24cr.x1mh8g0r.xexx8yu.x4uap5.x18d9i69.xkhd6sd.x16tdsg8.x1hl2dhg.xggy1nq.x1a2a7pz.notranslate._a6hd > span')[0].text\n",
    "\n",
    "    # print('like', like)\n",
    "  except:\n",
    "    like=''\n",
    "\n",
    "  try:\n",
    "    place = soup.select('div._ap3a > a.x1i10hfl')[0].text\n",
    "    # print('place',place)\n",
    "  except:\n",
    "    place=''\n",
    "\n",
    "  data = [content, date, like, place, tags]\n",
    "  return data\n",
    "\n",
    "def move_next(driver):\n",
    "  try:\n",
    "    right = driver.find_element(By.CSS_SELECTOR,'div._aaqg > button._abl-')\n",
    "    right.click()\n",
    "    time.sleep(3)\n",
    "  except:\n",
    "    print('no button')\n",
    "\n",
    "word_list=[  '서울비건맛집','서울비건카페', '서울비건식당','서울비건레스토랑']\n",
    "for word in word_list:\n",
    "  url=insta_searching(word)\n",
    "  driver.get(url)\n",
    "  time.sleep(7)\n",
    "  select_first(driver)\n",
    "  results=[]\n",
    "  target_cnt = 28\n",
    "  for idx in range(target_cnt):\n",
    "    try:\n",
    "      data = get_content(driver)\n",
    "      results.append(data)\n",
    "      move_next(driver)\n",
    "    except:\n",
    "      time.sleep(2)\n",
    "      move_next(driver)\n",
    "\n",
    "  print(len(results))\n",
    "\n",
    "  results_df = pd.DataFrame(results)\n",
    "  results_df.columns=['content','data','like','place','tags']\n",
    "  results_df.to_excel('./instagram_crawling_{}.xlsx'.format(word), index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ef07d7ffff8a449"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seoul_vegan_insta_df=pd.DataFrame([])\n",
    "word_list=[  '서울비건맛집',  '서울비건카페', '서울비건식당','서울비건레스토랑']\n",
    "file_list=[]\n",
    "for word in word_list:\n",
    "  file_list.append('./instagram_crawling_{}.xlsx'.format(word))\n",
    "  \n",
    "for file in file_list:\n",
    "  temp = pd.read_excel(file)\n",
    "  seoul_vegan_insta_df = pd.concat([seoul_vegan_insta_df,temp])\n",
    "\n",
    "seoul_vegan_insta_df.columns=['content','data','like','place','tags']\n",
    "seoul_vegan_insta_df.drop_duplicates(subset=['content'], inplace=True)\n",
    "seoul_vegan_insta_df.to_excel('./instagram_crawling_result-seoul-vegan-restaurant.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c52e3f7d40ea35d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_total = pd.read_excel('./instagram_crawling_result-seoul-vegan-restaurant.xlsx')\n",
    "tags_total=[]\n",
    "for tags in raw_total['tags']:\n",
    "  # print('tags',len(tags), tags)\n",
    "  if len(tags) == 2:\n",
    "    continue\n",
    "  tags_list = tags[2:-2].split(\"', '\")\n",
    "  for tag in tags_list:\n",
    "    # print('tag',tag)\n",
    "    tags_total.append(tag)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61e30422a4309c30"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print('len',len(tags_total))\n",
    "delete_word=['#존맛탱','#일러스트','#디엠']\n",
    "clean_tag_total = [] \n",
    "for tag in tags_total:\n",
    "  if tag not in delete_word:\n",
    "    clean_tag_total.append(tag)\n",
    "  \n",
    "tag_count = Counter(tags_total)\n",
    "clean_tag_total = Counter(clean_tag_total)\n",
    "clean_tag_total.most_common(50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3b54c07e2f48647"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from hangul_font import to_hangul_font\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "to_hangul_font()\n",
    "tag_count_df = pd.DataFrame(clean_tag_total.most_common(30))\n",
    "tag_count_df.columns = ['tags','counts']\n",
    "print(tag_count_df)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x='counts',y='tags',data=tag_count_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34f27439670e3b2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "  font_path = 'c:/Windows/Fonts/malgun.ttf'\n",
    "elif platform.system() == 'Darwin':\n",
    "  font_path = '/Users/$User/Library/Fonts/AppleGothic.ttf'\n",
    "  \n",
    "wordcloud=WordCloud(font_path=font_path,\n",
    "                    background_color='white',\n",
    "                    max_words=100,\n",
    "                    relative_scaling=0.3,\n",
    "                    width=800,\n",
    "                    height=400\n",
    "                    ).generate_from_frequencies(clean_tag_total)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.savefig('./seoul_vegan_tag_wordcloud.png')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "308ac358b45808a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "raw_total = pd.read_excel('./instagram_crawling_result-seoul-vegan-restaurant.xlsx')\n",
    "clean_location_total = []\n",
    "reg = re.compile('[0-9]')\n",
    "clean_location_total=[]\n",
    "for location in raw_total['place']:\n",
    "  # print(reg.findall(location))\n",
    "  if len(reg.findall(location)) == 0:\n",
    "    clean_location_total.append(location)\n",
    "\n",
    "clean_location_cnt = Counter(clean_location_total)\n",
    "# print(clean_location_cnt.most_common(40))\n",
    "location_count_df= pd.DataFrame(clean_location_cnt.most_common(40))\n",
    "location_count_df.columns=['place','counts']\n",
    "location_count_df.to_excel('./seoul_vegan_location_count.xlsx', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afa9133163ab82cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "locations = clean_location_cnt.keys()\n",
    "locations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a3e1e2c4a727dd6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def find_place(query):\n",
    "  \n",
    "  # 카카오 로컬 > 키워드로 검색하기 공식문서 https://developers.kakao.com/docs/latest/ko/local/dev-guide#search-by-keyword\n",
    "  url='https://dapi.kakao.com/v2/local/search/keyword.json?query={}'.format(query)\n",
    "  headers={\n",
    "    \"Authorization\":\"KakaoAK e1ff570612513d98daff33c7868daa5d\"\n",
    "  }\n",
    "  \n",
    "  places = requests.get(url,headers=headers).json()['documents']\n",
    "  place = places[0]\n",
    "  name=place['place_name']\n",
    "  x=place['x'] #경도\n",
    "  y=place['y'] #위도\n",
    "  \n",
    "  return [name,x,y,query]\n",
    "\n",
    "\n",
    "import time\n",
    "location_info_list = []\n",
    "for name in locations:\n",
    "  try:\n",
    "    data=find_place(name)\n",
    "    location_info_list.append(data)\n",
    "    time.sleep(0.5)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "location_info_list_df = pd.DataFrame(location_info_list)\n",
    "location_info_list_df.columns=['offical_name','latitude','longitude','place']\n",
    "location_info_list_df.to_excel('./seoul_vegan_location_info_list.xlsx', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbe069f67e034d27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "location_count_df=pd.read_excel('./seoul_vegan_location_count.xlsx', index_col=0)\n",
    "location_info_list_df=pd.read_excel('./seoul_vegan_location_info_list.xlsx')\n",
    "location_data = pd.merge(location_info_list_df,location_count_df,how='inner', left_on='place',right_index=True)\n",
    "location_data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b1370866b8400f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "location_data['place'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e34578f39079c880"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "location_data=location_data.pivot_table(\n",
    "    index=['place','latitude','longitude'],\n",
    "    values='counts',\n",
    "    aggfunc='sum'\n",
    ")\n",
    "location_data.head()\n",
    "location_data.to_excel('./seoul_vegan_location_pivot_data.xlsx')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86576e51fc9fcf45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "location_data = pd.read_excel('./seoul_vegan_location_pivot_data.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51767cb89ba66372"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "namsan=[37.55120584342893, 126.98346716392766]\n",
    "seoul_map = folium.Map(location=namsan,zoom_start=11)\n",
    "\n",
    "for idx in range(len(location_data)):\n",
    "  name = location_data['place'][idx]\n",
    "  cnt = location_data['counts'][idx]\n",
    "  size=int(cnt)*2\n",
    "  long = float(location_data['longitude'][idx]) #경도\n",
    "  lat = float(location_data['latitude'][idx]) #위도\n",
    "  print(name, cnt, long, lat)\n",
    "  folium.CircleMarker((lat,long), radius=size, color='red',popup=name).add_to(seoul_map)\n",
    "seoul_map.save('./seoul_map_new.html')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dc4b647edef6978"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "locations=[]\n",
    "names=[]\n",
    "\n",
    "for idx in range(len(location_data)):\n",
    "  data = location_data.iloc[idx]\n",
    "  # print(data)\n",
    "  locations.append((float(data['latitude']),float(data['longitude'])))\n",
    "  names.append(data['place'])\n",
    "\n",
    "namsan=[37.55120584342893, 126.98346716392766]\n",
    "seoul_map2 = folium.Map(location=namsan, zoom_start=11)\n",
    "marker_cluster=MarkerCluster(\n",
    "    locations=locations,\n",
    "    popups=names,\n",
    "    name='Seoul',\n",
    "    overlay=True,\n",
    "    control=True\n",
    ")\n",
    "\n",
    "# print(names)\n",
    "# print(locations)\n",
    "\n",
    "marker_cluster.add_to(seoul_map2)\n",
    "folium.LayerControl().add_to(seoul_map2)\n",
    "seoul_map2.save('./seoul_map2.html')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b7c6c636a659133"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_total = pd.read_excel('./instagram_crawling_result-seoul-vegan-restaurant.xlsx')\n",
    "select_word='망원'\n",
    "check_list=[]\n",
    "for content in raw_total['content']:\n",
    "  if select_word in content:\n",
    "    check_list.append(True)\n",
    "  else:\n",
    "    check_list.append(False)\n",
    "    \n",
    "select_df = raw_total[check_list]\n",
    "\n",
    "for idx in select_df.index:\n",
    "  print(select_df.loc[idx, 'content'])\n",
    "  print('-'*50)\n",
    "select_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46b098ddc9024a5d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
